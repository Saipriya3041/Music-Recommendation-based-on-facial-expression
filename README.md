# Mini-Project On Music Recommendation Based On Facial Expression

---

# 🎵 **Emotion-Based Music Recommendation System** 🎭🎶

A cutting-edge project that bridges **Artificial Intelligence**, **Computer Vision**, and **Music** to provide a personalized, emotion-based music recommendation experience. This system recognizes facial expressions, detects emotions, and curates music to enhance the user's mood and well-being.

---

## 🚀 **Features**
- **Facial Expression Detection**: Captures real-time facial expressions using a webcam and processes them into grayscale images for analysis.
- **Emotion Recognition**: Detects seven key emotions — Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise — using the FER-2013 dataset.
- **Personalized Music Recommendation**: Suggests music that matches the user's emotional state, boosting mood and productivity.
- **Interactive Supportive Text**: Displays uplifting messages alongside music to cheer up users.
- **Audio Conversion**: Converts `.mpeg` files to `.wav` for seamless music playback.
- ![image](https://github.com/user-attachments/assets/e9b6097e-b162-4266-9a6e-88980f195e29)

---

## 🛠️ **Technologies Used**
- **Deep Learning**: Convolutional Neural Networks (CNNs) built using TensorFlow/Keras for emotion recognition.
- **Computer Vision**: OpenCV for image processing and face detection using Haar Cascade Classifier.
- **Audio Processing**: Libraries like Librosa and Pydub for audio conversion and playback.
- **Python Ecosystem**: NumPy, Pandas, Matplotlib, Seaborn for data manipulation, visualization, and preprocessing.

---

## 📂 **Dataset**
- **FER-2013 Dataset**:
  - 48x48 grayscale images of facial expressions.
  - 7 emotion categories.
  - 35,887 images split into training and testing datasets.
  - The training dataset consists of 26915 images and the testing dataset contains 8972 images.
  - For data set visit https://www.kaggle.com and search fer2013 dataset.

---

## 🔑 **Key Advantages**
- **Personalized Experience**: Tailors music to the user's emotions, enhancing mood and mental well-being.
- **Therapeutic Applications**: Supports mental health by recommending soothing music based on emotional state.
- **Stress Reduction**: Helps students and employees relax and rejuvenate during breaks.
- **Interactive Installations**: Ideal for museums, retail, and public spaces to create immersive experiences.

---

## 🌟 **Applications**
- **Mental Health Therapy**: Aiding individuals in managing anxiety, depression, and stress.
- **Interactive Environments**: Museums, public spaces, and retail stores for dynamic user experiences.
- **Vehicle Integration**: Personalized music selection during drives.
- **Online Learning**: Monitoring and enhancing student engagement.

---

## 🔧 **Requirements**
- Python, TensorFlow, Keras, OpenCV, Matplotlib, Pandas, Librosa, Pydub, NumPy, and more.
- Google Colab for development and model training.

---

## 👨‍💻 **Setup & Usage**
1. Clone the repository:
   ```bash
   git clone https://github.com/Koppisettibhoomika/Mini-Project-Music-Recommendation-Based-On-Facial-Expression
   
   ```
   
3. Run the program on Google Colab for webcam functionality and model execution.

---

## 📈 **How It Works**
1. Capture facial expressions via webcam.
2. Process the image (grayscale conversion, face detection, resizing).
3. Use CNN to recognize emotions.
4. Recommend music that matches the detected emotion.
5. Display supportive text to uplift the user's mood.

---

## System Designs 🖥️🎵
![image](https://github.com/user-attachments/assets/0b42ecb1-e3a0-425e-ac78-3688813053fd)
![image](https://github.com/user-attachments/assets/7077242a-fa2b-49f5-a504-b433c93fc8d7)
![image](https://github.com/user-attachments/assets/c69f3438-66ba-4b09-8a17-d8b3e8d2c642)
![image](https://github.com/user-attachments/assets/210ebd09-7707-49aa-94e9-4ff5cf7702fb)
![image](https://github.com/user-attachments/assets/9ef1030c-d57f-4619-83b4-5244e2bd90d4)
![image](https://github.com/user-attachments/assets/888cb85a-9c0e-49bf-8ed7-fbf43c3f2c3a)

---

## 🎯 **Future Enhancements**
- **Multi-language Music Recommendation**: Expanding to support diverse user preferences.
- **Real-Time Feedback**: Dynamic updates to music recommendations based on mood shifts.
- **Cross-Platform Integration**: Making the system compatible with mobile and IoT devices.

---

## ❤️ **Acknowledgments**
Special thanks to:
- The creators of the FER-2013 dataset.
- Open-source contributors whose libraries made this project possible.



